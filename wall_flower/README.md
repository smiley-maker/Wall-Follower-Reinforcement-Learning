# Wall Following Using Reinforcement Learning
This project uses Q-Learning to train a robot to follow walls on its left in a simulated environment using ROS and Python. The robot was tasked with following walls consistently without straying to far from the left wall or getting to close to it. Further, it needed to avoid obstacles along the way.
## Startup:
To initialize the Gazebo environment, run the following command:
```console
roslaunch wall_flower wallfollow.launch
```
This will open a Gazebo window with the Turtlebot3 Waffle Pi and the designated environment.
### Note that you must be cd'd into wall_flower/src before running any of the training or testing modes. 

## Training:
Before training, make sure to update the desired Q table file name in make_table.py within the saveToJSONI() function. 

In order to perform reinforcement learning to train the robot to follow walls, run the following command after opening Gazebo.
```console
rosrun wall_flower wall_flower.py
```
This will prompt you to select a mode (train or test). Train will launch reset the Q-table and begin with either Q-Learning or SARSA, which you will also have to specifiy in the next question.
## Testing:
To test the Q-table generated by training, run the following command:
```
rosrun wall_flower wall_flower.py
```
Similarly to training, to test the Q-table, type "test" when the prompt appears. This should launch the demonstration in Gazebo.
## Videos:
### Part One YouTube Video:
This video shows a manually programmed Q-Table follow a straight wall.
https://youtu.be/OW_JivZD3K4
### Part Two YouTube Video